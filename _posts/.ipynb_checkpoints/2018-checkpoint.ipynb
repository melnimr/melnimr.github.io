{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: Keras for TalkingData\n",
    "excerpt: Deep Learning for Classification.\n",
    "---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "import gc\n",
    "\n",
    "path = '../input/'\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "print('load train....')\n",
    "# we save only day 9\n",
    "train_df = pd.read_csv(path+\"train.csv\", dtype=dtypes, skiprows = range(1, 131886954), usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "print('load test....')\n",
    "test_df = pd.read_csv(path+\"test.csv\", dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "len_train = len(train_df)\n",
    "train_df=train_df.append(test_df)\n",
    "del test_df; gc.collect()\n",
    "\n",
    "print('hour, day, wday....')\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "train_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\n",
    "train_df['wday']  = pd.to_datetime(train_df.click_time).dt.dayofweek.astype('uint8')\n",
    "print('grouping by ip-day-hour combination....')\n",
    "gp = train_df[['ip','day','hour','channel']].groupby(by=['ip','day','hour'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'qty'})\n",
    "train_df = train_df.merge(gp, on=['ip','day','hour'], how='left')\n",
    "del gp; gc.collect()\n",
    "print('group by ip-app combination....')\n",
    "gp = train_df[['ip','app', 'channel']].groupby(by=['ip', 'app'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_count'})\n",
    "train_df = train_df.merge(gp, on=['ip','app'], how='left')\n",
    "del gp; gc.collect()\n",
    "print('group by ip-app-os combination....')\n",
    "gp = train_df[['ip','app', 'os', 'channel']].groupby(by=['ip', 'app', 'os'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_os_count'})\n",
    "train_df = train_df.merge(gp, on=['ip','app', 'os'], how='left')\n",
    "del gp; gc.collect()\n",
    "print(\"vars and data type....\")\n",
    "train_df['qty'] = train_df['qty'].astype('uint16')\n",
    "train_df['ip_app_count'] = train_df['ip_app_count'].astype('uint16')\n",
    "train_df['ip_app_os_count'] = train_df['ip_app_os_count'].astype('uint16')\n",
    "print(\"label encoding....\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_df[['app','device','os', 'channel', 'hour', 'day', 'wday']].apply(LabelEncoder().fit_transform)\n",
    "print ('final part of preparation....')\n",
    "test_df = train_df[len_train:]\n",
    "train_df = train_df[:len_train]\n",
    "y_train = train_df['is_attributed'].values\n",
    "train_df.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)\n",
    "\n",
    "print ('neural network....')\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "max_app = np.max([train_df['app'].max(), test_df['app'].max()])+1\n",
    "max_ch = np.max([train_df['channel'].max(), test_df['channel'].max()])+1\n",
    "max_dev = np.max([train_df['device'].max(), test_df['device'].max()])+1\n",
    "max_os = np.max([train_df['os'].max(), test_df['os'].max()])+1\n",
    "max_h = np.max([train_df['hour'].max(), test_df['hour'].max()])+1\n",
    "max_d = np.max([train_df['day'].max(), test_df['day'].max()])+1\n",
    "max_wd = np.max([train_df['wday'].max(), test_df['wday'].max()])+1\n",
    "max_qty = np.max([train_df['qty'].max(), test_df['qty'].max()])+1\n",
    "max_c1 = np.max([train_df['ip_app_count'].max(), test_df['ip_app_count'].max()])+1\n",
    "max_c2 = np.max([train_df['ip_app_os_count'].max(), test_df['ip_app_os_count'].max()])+1\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'd': np.array(dataset.day),\n",
    "        'wd': np.array(dataset.wday),\n",
    "        'qty': np.array(dataset.qty),\n",
    "        'c1': np.array(dataset.ip_app_count),\n",
    "        'c2': np.array(dataset.ip_app_os_count)\n",
    "    }\n",
    "    return X\n",
    "train_df = get_keras_data(train_df)\n",
    "\n",
    "emb_n = 50\n",
    "dense_n = 1000\n",
    "in_app = Input(shape=[1], name = 'app')\n",
    "emb_app = Embedding(max_app, emb_n)(in_app)\n",
    "in_ch = Input(shape=[1], name = 'ch')\n",
    "emb_ch = Embedding(max_ch, emb_n)(in_ch)\n",
    "in_dev = Input(shape=[1], name = 'dev')\n",
    "emb_dev = Embedding(max_dev, emb_n)(in_dev)\n",
    "in_os = Input(shape=[1], name = 'os')\n",
    "emb_os = Embedding(max_os, emb_n)(in_os)\n",
    "in_h = Input(shape=[1], name = 'h')\n",
    "emb_h = Embedding(max_h, emb_n)(in_h) \n",
    "in_d = Input(shape=[1], name = 'd')\n",
    "emb_d = Embedding(max_d, emb_n)(in_d) \n",
    "in_wd = Input(shape=[1], name = 'wd')\n",
    "emb_wd = Embedding(max_wd, emb_n)(in_wd) \n",
    "in_qty = Input(shape=[1], name = 'qty')\n",
    "emb_qty = Embedding(max_qty, emb_n)(in_qty) \n",
    "in_c1 = Input(shape=[1], name = 'c1')\n",
    "emb_c1 = Embedding(max_c1, emb_n)(in_c1) \n",
    "in_c2 = Input(shape=[1], name = 'c2')\n",
    "emb_c2 = Embedding(max_c2, emb_n)(in_c2) \n",
    "fe = concatenate([(emb_app), (emb_ch), (emb_dev), (emb_os), (emb_h), \n",
    "                 (emb_d), (emb_wd), (emb_qty), (emb_c1), (emb_c2)])\n",
    "s_dout = SpatialDropout1D(0.2)(fe)\n",
    "x = Flatten()(s_dout)\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "outp = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=[in_app,in_ch,in_dev,in_os,in_h,in_d,in_wd,in_qty,in_c1,in_c2], outputs=outp)\n",
    "\n",
    "batch_size = 20000\n",
    "epochs = 2\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(train_df) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.001, 0.0001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.001, decay=lr_decay)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_df, y_train, batch_size=batch_size, epochs=2, shuffle=True, verbose=2)\n",
    "del train_df, y_train; gc.collect()\n",
    "model.save_weights('dl_support.h5')\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_df['click_id'].astype('int')\n",
    "test_df.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)\n",
    "test_df = get_keras_data(test_df)\n",
    "\n",
    "print(\"predicting....\")\n",
    "sub['is_attributed'] = model.predict(test_df, batch_size=batch_size, verbose=2)\n",
    "del test_df; gc.collect()\n",
    "print(\"writing....\")\n",
    "sub.to_csv('dl_support.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "# write now i don't use validation set\n",
    "# since the data is imbalanced, i can't understand how we can separate data the right way\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
